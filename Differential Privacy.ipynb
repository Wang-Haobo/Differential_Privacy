{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0317b7eb-a515-4df6-925b-e947d00c458b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:45:58.890393600Z",
     "start_time": "2025-06-24T11:45:57.029123Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'columns': ['Timestamp',\n  'Record number',\n  'Average Water Speed',\n  'Average Water Direction',\n  'Chlorophyll',\n  'Temperature',\n  'Dissolved Oxygen',\n  'Dissolved Oxygen (%Saturation)',\n  'pH',\n  'Salinity',\n  'Specific Conductance',\n  'Turbidity'],\n 'head':         Timestamp  Record number  Average Water Speed  \\\n 0  2023/8/9 13:00           1693                5.314   \n 1  2023/8/9 13:30           1694                5.088   \n 2  2023/8/9 14:00           1695                5.836   \n 3  2023/8/9 14:30           1696                1.530   \n 4  2023/8/9 15:00           1697                6.343   \n \n    Average Water Direction  Chlorophyll  Temperature  Dissolved Oxygen  \\\n 0                   50.605        1.557       19.346             7.885   \n 1                   34.550        1.299       19.404             7.804   \n 2                  154.556        2.182       19.443             7.930   \n 3                   17.843        2.112       19.549             7.912   \n 4                   78.149        2.539       19.591             8.113   \n \n    Dissolved Oxygen (%Saturation)     pH  Salinity  Specific Conductance  \\\n 0                         105.210  8.169    34.809                52.714   \n 1                         104.222  8.162    34.776                52.668   \n 2                         106.005  8.169    34.822                52.730   \n 3                         105.963  8.165    34.808                52.712   \n 4                         108.773  8.178    34.850                52.769   \n \n    Turbidity  \n 0      2.085  \n 1      2.296  \n 2      2.081  \n 3      2.291  \n 4      2.014  ,\n 'summary':              Timestamp  Record number  Average Water Speed  \\\n count            19149   19149.000000         19149.000000   \n unique           18997            NaN                  NaN   \n top     2023/8/26 9:30            NaN                  NaN   \n freq                 2            NaN                  NaN   \n mean               NaN   20312.232493            16.353249   \n std                NaN    8571.348080            13.033747   \n min                NaN    1693.000000             0.016000   \n 25%                NaN   17198.000000             6.340000   \n 50%                NaN   22029.000000            12.805000   \n 75%                NaN   26867.000000            22.943000   \n max                NaN   32361.000000            89.912000   \n \n         Average Water Direction   Chlorophyll   Temperature  Dissolved Oxygen  \\\n count              19149.000000  19149.000000  19149.000000      19149.000000   \n unique                      NaN           NaN           NaN               NaN   \n top                         NaN           NaN           NaN               NaN   \n freq                        NaN           NaN           NaN               NaN   \n mean                 175.725639      2.812142     24.090088          6.811035   \n std                  103.553981      1.809513      3.770534          0.629402   \n min                    0.020000      0.106000     17.000000          3.806000   \n 25%                   85.313000      1.564000     20.661000          6.407000   \n 50%                  171.286000      2.425000     24.839000          6.839000   \n 75%                  266.066000      3.585000     27.272000          7.245000   \n max                  359.994000     43.301000     32.063000          9.260000   \n \n         Dissolved Oxygen (%Saturation)           pH      Salinity  \\\n count                     19149.000000  19149.00000  19149.000000   \n unique                             NaN          NaN           NaN   \n top                                NaN          NaN           NaN   \n freq                               NaN          NaN           NaN   \n mean                         96.067649      8.09484     30.128649   \n std                           8.352748      0.08057      3.420853   \n min                          51.836000      7.30900      0.158000   \n 25%                          91.147000      8.05300     28.816000   \n 50%                          95.864000      8.10800     29.744000   \n 75%                         101.089000      8.15400     31.515000   \n max                         134.082000      8.25300     36.000000   \n \n         Specific Conductance     Turbidity  \n count           19149.000000  19149.000000  \n unique                   NaN           NaN  \n top                      NaN           NaN  \n freq                     NaN           NaN  \n mean               46.387312      4.543217  \n std                 4.762702      4.768920  \n min                 0.334000      0.365000  \n 25%                44.561000      2.630000  \n 50%                45.884000      3.236000  \n 75%                48.420000      4.229000  \n max                54.506000     49.869000  }"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 加载用户上传的文件\n",
    "file_path = 'data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 查看数据的基本信息\n",
    "data_info = {\n",
    "    \"columns\": data.columns.tolist(),\n",
    "    \"head\": data.head(),\n",
    "    \"summary\": data.describe(include='all')\n",
    "}\n",
    "\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c798581a-9c6a-4dfb-979e-ba89bbf22ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:45:58.942541500Z",
     "start_time": "2025-06-24T11:45:58.889369600Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'columns': ['Timestamp',\n  'Record number',\n  'Average Water Speed',\n  'Average Water Direction',\n  'Chlorophyll',\n  'Temperature',\n  'Dissolved Oxygen',\n  'Dissolved Oxygen (%Saturation)',\n  'pH',\n  'Salinity',\n  'Specific Conductance',\n  'Turbidity'],\n 'head':         Timestamp  Record number  Average Water Speed  \\\n 0  2023/8/9 13:00           1693                5.314   \n 1  2023/8/9 13:30           1694                5.088   \n 2  2023/8/9 14:00           1695                5.836   \n 3  2023/8/9 14:30           1696                1.530   \n 4  2023/8/9 15:00           1697                6.343   \n \n    Average Water Direction  Chlorophyll  Temperature  Dissolved Oxygen  \\\n 0                   50.605        1.557       19.346             7.885   \n 1                   34.550        1.299       19.404             7.804   \n 2                  154.556        2.182       19.443             7.930   \n 3                   17.843        2.112       19.549             7.912   \n 4                   78.149        2.539       19.591             8.113   \n \n    Dissolved Oxygen (%Saturation)     pH  Salinity  Specific Conductance  \\\n 0                         105.210  8.169    34.809                52.714   \n 1                         104.222  8.162    34.776                52.668   \n 2                         106.005  8.169    34.822                52.730   \n 3                         105.963  8.165    34.808                52.712   \n 4                         108.773  8.178    34.850                52.769   \n \n    Turbidity  \n 0      2.085  \n 1      2.296  \n 2      2.081  \n 3      2.291  \n 4      2.014  ,\n 'summary':              Timestamp  Record number  Average Water Speed  \\\n count            19149   19149.000000         19149.000000   \n unique           18997            NaN                  NaN   \n top     2023/8/26 9:30            NaN                  NaN   \n freq                 2            NaN                  NaN   \n mean               NaN   20312.232493            16.353249   \n std                NaN    8571.348080            13.033747   \n min                NaN    1693.000000             0.016000   \n 25%                NaN   17198.000000             6.340000   \n 50%                NaN   22029.000000            12.805000   \n 75%                NaN   26867.000000            22.943000   \n max                NaN   32361.000000            89.912000   \n \n         Average Water Direction   Chlorophyll   Temperature  Dissolved Oxygen  \\\n count              19149.000000  19149.000000  19149.000000      19149.000000   \n unique                      NaN           NaN           NaN               NaN   \n top                         NaN           NaN           NaN               NaN   \n freq                        NaN           NaN           NaN               NaN   \n mean                 175.725639      2.812142     24.090088          6.811035   \n std                  103.553981      1.809513      3.770534          0.629402   \n min                    0.020000      0.106000     17.000000          3.806000   \n 25%                   85.313000      1.564000     20.661000          6.407000   \n 50%                  171.286000      2.425000     24.839000          6.839000   \n 75%                  266.066000      3.585000     27.272000          7.245000   \n max                  359.994000     43.301000     32.063000          9.260000   \n \n         Dissolved Oxygen (%Saturation)           pH      Salinity  \\\n count                     19149.000000  19149.00000  19149.000000   \n unique                             NaN          NaN           NaN   \n top                                NaN          NaN           NaN   \n freq                               NaN          NaN           NaN   \n mean                         96.067649      8.09484     30.128649   \n std                           8.352748      0.08057      3.420853   \n min                          51.836000      7.30900      0.158000   \n 25%                          91.147000      8.05300     28.816000   \n 50%                          95.864000      8.10800     29.744000   \n 75%                         101.089000      8.15400     31.515000   \n max                         134.082000      8.25300     36.000000   \n \n         Specific Conductance     Turbidity  \n count           19149.000000  19149.000000  \n unique                   NaN           NaN  \n top                      NaN           NaN  \n freq                     NaN           NaN  \n mean               46.387312      4.543217  \n std                 4.762702      4.768920  \n min                 0.334000      0.365000  \n 25%                44.561000      2.630000  \n 50%                45.884000      3.236000  \n 75%                48.420000      4.229000  \n max                54.506000     49.869000  }"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 加载用户上传的文件\n",
    "file_path = 'data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 查看数据的基本信息\n",
    "data_info = {\n",
    "    \"columns\": data.columns.tolist(),\n",
    "    \"head\": data.head(),\n",
    "    \"summary\": data.describe(include='all')\n",
    "}\n",
    "\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "acf6ca18-b635-458f-91a4-66199ac93e9d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:45:59.004094400Z",
     "start_time": "2025-06-24T11:45:58.935369400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'columns': ['Timestamp',\n  'Record number',\n  'Average Water Speed',\n  'Average Water Direction',\n  'Chlorophyll',\n  'Temperature',\n  'Dissolved Oxygen',\n  'Dissolved Oxygen (%Saturation)',\n  'pH',\n  'Salinity',\n  'Specific Conductance',\n  'Turbidity'],\n 'head':         Timestamp  Record number  Average Water Speed  \\\n 0  2023/8/9 13:00           1693                5.314   \n 1  2023/8/9 13:30           1694                5.088   \n 2  2023/8/9 14:00           1695                5.836   \n 3  2023/8/9 14:30           1696                1.530   \n 4  2023/8/9 15:00           1697                6.343   \n \n    Average Water Direction  Chlorophyll  Temperature  Dissolved Oxygen  \\\n 0                   50.605        1.557       19.346             7.885   \n 1                   34.550        1.299       19.404             7.804   \n 2                  154.556        2.182       19.443             7.930   \n 3                   17.843        2.112       19.549             7.912   \n 4                   78.149        2.539       19.591             8.113   \n \n    Dissolved Oxygen (%Saturation)     pH  Salinity  Specific Conductance  \\\n 0                         105.210  8.169    34.809                52.714   \n 1                         104.222  8.162    34.776                52.668   \n 2                         106.005  8.169    34.822                52.730   \n 3                         105.963  8.165    34.808                52.712   \n 4                         108.773  8.178    34.850                52.769   \n \n    Turbidity  \n 0      2.085  \n 1      2.296  \n 2      2.081  \n 3      2.291  \n 4      2.014  ,\n 'summary':              Timestamp  Record number  Average Water Speed  \\\n count            19149   19149.000000         19149.000000   \n unique           18997            NaN                  NaN   \n top     2023/8/26 9:30            NaN                  NaN   \n freq                 2            NaN                  NaN   \n mean               NaN   20312.232493            16.353249   \n std                NaN    8571.348080            13.033747   \n min                NaN    1693.000000             0.016000   \n 25%                NaN   17198.000000             6.340000   \n 50%                NaN   22029.000000            12.805000   \n 75%                NaN   26867.000000            22.943000   \n max                NaN   32361.000000            89.912000   \n \n         Average Water Direction   Chlorophyll   Temperature  Dissolved Oxygen  \\\n count              19149.000000  19149.000000  19149.000000      19149.000000   \n unique                      NaN           NaN           NaN               NaN   \n top                         NaN           NaN           NaN               NaN   \n freq                        NaN           NaN           NaN               NaN   \n mean                 175.725639      2.812142     24.090088          6.811035   \n std                  103.553981      1.809513      3.770534          0.629402   \n min                    0.020000      0.106000     17.000000          3.806000   \n 25%                   85.313000      1.564000     20.661000          6.407000   \n 50%                  171.286000      2.425000     24.839000          6.839000   \n 75%                  266.066000      3.585000     27.272000          7.245000   \n max                  359.994000     43.301000     32.063000          9.260000   \n \n         Dissolved Oxygen (%Saturation)           pH      Salinity  \\\n count                     19149.000000  19149.00000  19149.000000   \n unique                             NaN          NaN           NaN   \n top                                NaN          NaN           NaN   \n freq                               NaN          NaN           NaN   \n mean                         96.067649      8.09484     30.128649   \n std                           8.352748      0.08057      3.420853   \n min                          51.836000      7.30900      0.158000   \n 25%                          91.147000      8.05300     28.816000   \n 50%                          95.864000      8.10800     29.744000   \n 75%                         101.089000      8.15400     31.515000   \n max                         134.082000      8.25300     36.000000   \n \n         Specific Conductance     Turbidity  \n count           19149.000000  19149.000000  \n unique                   NaN           NaN  \n top                      NaN           NaN  \n freq                     NaN           NaN  \n mean               46.387312      4.543217  \n std                 4.762702      4.768920  \n min                 0.334000      0.365000  \n 25%                44.561000      2.630000  \n 50%                45.884000      3.236000  \n 75%                48.420000      4.229000  \n max                54.506000     49.869000  }"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "# 加载用户上传的文件\n",
    "file_path = 'data.csv'\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# 查看数据的基本信息\n",
    "data_info = {\n",
    "    \"columns\": data.columns.tolist(),\n",
    "    \"head\": data.head(),\n",
    "    \"summary\": data.describe(include='all')\n",
    "}\n",
    "\n",
    "data_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bb2ad9e-adeb-4f67-8df7-45d5d92ba035",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:45:59.025641700Z",
     "start_time": "2025-06-24T11:45:58.982230100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(     Grid  Stay_Time  Duration\n 0  (0, 0)          4         1\n 1  (0, 0)         11         1\n 2  (0, 0)         30         1\n 3  (0, 0)         56         1\n 4  (0, 0)         83         1,\n      Grid  Visit_Frequency\n 0  (1, 1)              673\n 1  (1, 2)              598\n 2  (1, 5)              549\n 3  (1, 6)              544\n 4  (0, 2)              534)"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: 网格化映射 (将地理或水流方向数据分配到离散网格中)\n",
    "# 假设使用水流方向和水速来定义轨迹\n",
    "data['Grid_X'] = np.floor(data['Average Water Speed'] / 5).astype(int)  # 网格化水速\n",
    "data['Grid_Y'] = np.floor(data['Average Water Direction'] / 45).astype(int)  # 网格化方向\n",
    "\n",
    "# Step 2: 计算转移矩阵、停留时间、访问频次\n",
    "data['Grid'] = list(zip(data['Grid_X'], data['Grid_Y']))\n",
    "\n",
    "# 计算停留时间（连续记录在相同网格的时间）\n",
    "data['Stay_Time'] = (data['Grid'] != data['Grid'].shift(1)).cumsum()\n",
    "stay_times = data.groupby(['Grid', 'Stay_Time']).size().reset_index(name='Duration')\n",
    "\n",
    "# 计算访问频次（每个网格被访问的次数）\n",
    "visit_frequencies = data['Grid'].value_counts().reset_index()\n",
    "visit_frequencies.columns = ['Grid', 'Visit_Frequency']\n",
    "\n",
    "# 输出计算结果\n",
    "stay_times_info = stay_times.head()\n",
    "visit_frequencies_info = visit_frequencies.head()\n",
    "\n",
    "stay_times_info, visit_frequencies_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b241264-86b4-4390-aaa0-0dbced832468",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.655698700Z",
     "start_time": "2025-06-24T11:45:59.012258600Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.spatial.distance import euclidean\n",
    "from collections import defaultdict\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfbf56b5-f5c4-4360-9e6d-8523ca3e14c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.694680200Z",
     "start_time": "2025-06-24T11:46:00.657716500Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 1: 网格化映射 (将地理或水流方向数据分配到离散网格中)\n",
    "data['Grid_X'] = np.floor(data['Average Water Speed'] / 5).astype(int)  # 网格化水速\n",
    "data['Grid_Y'] = np.floor(data['Average Water Direction'] / 45).astype(int)  # 网格化方向\n",
    "data['Grid'] = list(zip(data['Grid_X'], data['Grid_Y']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "147f41fd-a436-4015-8fba-e03fa271d582",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.708464300Z",
     "start_time": "2025-06-24T11:46:00.687592Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: 计算转移矩阵、停留时间、访问频次\n",
    "data['Stay_Time'] = (data['Grid'] != data['Grid'].shift(1)).cumsum()\n",
    "stay_times = data.groupby(['Grid', 'Stay_Time']).size().reset_index(name='Duration')\n",
    "visit_frequencies = data['Grid'].value_counts().reset_index()\n",
    "visit_frequencies.columns = ['Grid', 'Visit_Frequency']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3604474-4700-4ae7-9962-8e976cb09f32",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.731383800Z",
     "start_time": "2025-06-24T11:46:00.703411200Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 3: 隐私预算分配\n",
    "visit_frequencies['Privacy_Budget'] = 1 / (1 + visit_frequencies['Visit_Frequency'])\n",
    "privacy_budget_dict = dict(zip(visit_frequencies['Grid'], visit_frequencies['Privacy_Budget']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14fcaeb-0f52-47b5-99ec-36fd4b3c3050",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.887002600Z",
     "start_time": "2025-06-24T11:46:00.718108600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: 构建马尔可夫转移矩阵\n",
    "transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "for i in range(len(data) - 1):\n",
    "    current_state = data['Grid'].iloc[i]\n",
    "    next_state = data['Grid'].iloc[i + 1]\n",
    "    transition_counts[current_state][next_state] += 1\n",
    "\n",
    "transition_matrix = {state: {next_state: count / sum(next_states.values())\n",
    "                             for next_state, count in next_states.items()}\n",
    "                     for state, next_states in transition_counts.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4296091a-a21c-48d8-b898-67948cb4e314",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.903452300Z",
     "start_time": "2025-06-24T11:46:00.890358700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 5: 生成加噪轨迹\n",
    "def generate_noisy_trajectory(start, length, transition_matrix, privacy_budget_dict, noise_scale=0.1):\n",
    "    # 最终输出的轨迹，可以包含浮点数\n",
    "    output_trajectory = [start_point] \n",
    "    \n",
    "    # 用于在转移矩阵中查询的当前离散状态\n",
    "    current_discrete_state = start_point\n",
    "\n",
    "    for _ in range(length - 1):\n",
    "        # 检查当前的离散状态是否存在于转移矩阵中\n",
    "        if current_discrete_state not in transition_matrix:\n",
    "            # 如果当前状态没有出度（即无法转移到任何其他状态），则停止生成\n",
    "            break\n",
    "        \n",
    "        # 1. 使用离散状态进行查询\n",
    "        next_states_options = list(transition_matrix[current_discrete_state].keys())\n",
    "        probabilities = list(transition_matrix[current_discrete_state].values())\n",
    "        \n",
    "        # 如果概率列表为空或总和为0，也停止\n",
    "        if not probabilities or sum(probabilities) == 0:\n",
    "            break\n",
    "\n",
    "        # 2. 选择下一个 *离散* 状态\n",
    "        next_discrete_state = random.choices(next_states_options, probabilities)[0]\n",
    "        \n",
    "        # 3. 对这个新的离散状态添加噪声，得到一个连续坐标\n",
    "        noise = random.gauss(0, privacy_budget_dict.get(next_discrete_state, noise_scale))\n",
    "        noisy_output_state = (next_discrete_state[0] + noise, next_discrete_state[1] + noise)\n",
    "        \n",
    "        # 4. 将加噪后的连续坐标存入输出轨迹\n",
    "        output_trajectory.append(noisy_output_state)\n",
    "        \n",
    "        # 5. 更新 *离散* 状态，用于下一次循环\n",
    "        current_discrete_state = next_discrete_state\n",
    "        \n",
    "    return output_trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# --- 数据准备：为DP-Star算法切分轨迹 ---\n",
    "# DP-Star需要一个轨迹数据库来学习转移模式。\n",
    "# 我们将原始的长轨迹切分为多条固定长度的子轨迹。\n",
    "# 我们使用您在后续单元中定义的 trajectory_length = 100。\n",
    "\n",
    "trajectory_length_for_db = 100\n",
    "trajectories_db = []\n",
    "grid_trajectory = list(data['Grid']) # 转换为列表方便切片\n",
    "\n",
    "for i in range(0, len(grid_trajectory) - trajectory_length_for_db + 1, trajectory_length_for_db):\n",
    "    trajectories_db.append(grid_trajectory[i : i + trajectory_length_for_db])\n",
    "\n",
    "\n",
    "def dp_star_synthesis(trajectories, epsilon, start_point, length, sensitivity=1):\n",
    "    \"\"\"\n",
    "    实现一个一阶的 DP-Star 算法来生成合成轨迹。\n",
    "    它通过对转移计数添加拉普拉斯噪声来实现差分隐私。\n",
    "    \"\"\"\n",
    "    # 1. 基于轨迹数据库构建转移计数器\n",
    "    transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for trajectory in trajectories:\n",
    "        for i in range(len(trajectory) - 1):\n",
    "            current_state = trajectory[i]\n",
    "            next_state = trajectory[i+1]\n",
    "            transition_counts[current_state][next_state] += 1\n",
    "            \n",
    "    # 2. 对计数值添加拉普拉斯噪声\n",
    "    scale = sensitivity / epsilon\n",
    "    noisy_transition_counts = defaultdict(lambda: defaultdict(float))\n",
    "    for state, next_states in transition_counts.items():\n",
    "        for next_state, count in next_states.items():\n",
    "            noisy_count = count + np.random.laplace(0, scale)\n",
    "            # 后处理：确保计数非负\n",
    "            noisy_transition_counts[state][next_state] = max(0, noisy_count)\n",
    "\n",
    "    # 3. 将加噪后的计数转换为转移概率矩阵\n",
    "    noisy_transition_matrix = {}\n",
    "    for state, next_states in noisy_transition_counts.items():\n",
    "        total_count = sum(next_states.values())\n",
    "        if total_count > 0:\n",
    "            noisy_transition_matrix[state] = {\n",
    "                next_state: count / total_count \n",
    "                for next_state, count in next_states.items()\n",
    "            }\n",
    "    \n",
    "    # 4. 基于加噪的转移矩阵生成合成轨迹\n",
    "    synthetic_trajectory = [start_point]\n",
    "    current_state = start_point\n",
    "    \n",
    "    for _ in range(length - 1):\n",
    "        if current_state not in noisy_transition_matrix or not noisy_transition_matrix[current_state]:\n",
    "            break # 如果没有可转移的状态，则停止\n",
    "            \n",
    "        possible_next_states = list(noisy_transition_matrix[current_state].keys())\n",
    "        probabilities = list(noisy_transition_matrix[current_state].values())\n",
    "        \n",
    "        if sum(probabilities) > 0:\n",
    "            next_state = random.choices(possible_next_states, weights=probabilities, k=1)[0]\n",
    "            synthetic_trajectory.append(next_state)\n",
    "            current_state = next_state\n",
    "        else:\n",
    "            break # 如果所有转移概率都为0，则停止\n",
    "            \n",
    "    return synthetic_trajectory"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.933015500Z",
     "start_time": "2025-06-24T11:46:00.906552400Z"
    }
   },
   "id": "c2fbfd19b6c2c83"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9513a3ea-691f-4c82-ba4c-a53ae101aec0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:46:00.951015900Z",
     "start_time": "2025-06-24T11:46:00.936016100Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# Step 6: 计算弗雷歇距离\n",
    "def frechet_distance(P, Q):\n",
    "    len_p = len(P)\n",
    "    len_q = len(Q)\n",
    "    ca = np.full((len_p, len_q), -1.0)\n",
    "\n",
    "    def c(i, j):\n",
    "        if ca[i, j] > -1:\n",
    "            return ca[i, j]\n",
    "        if i == 0 and j == 0:\n",
    "            ca[i, j] = euclidean(P[0], Q[0])\n",
    "        elif i > 0 and j == 0:\n",
    "            ca[i, j] = max(c(i - 1, 0), euclidean(P[i], Q[0]))\n",
    "        elif i == 0 and j > 0:\n",
    "            ca[i, j] = max(c(0, j - 1), euclidean(P[0], Q[j]))\n",
    "        elif i > 0 and j > 0:\n",
    "            ca[i, j] = max(min(c(i - 1, j), c(i - 1, j - 1), c(i, j - 1)), euclidean(P[i], Q[j]))\n",
    "        else:\n",
    "            ca[i, j] = float('inf')\n",
    "        return ca[i, j]\n",
    "\n",
    "    return c(len_p - 1, len_q - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c9744da59752d69a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:29.049894800Z",
     "start_time": "2025-06-24T11:51:29.026862Z"
    }
   },
   "outputs": [],
   "source": [
    "trajectory_length = 100\n",
    "start_point = data['Grid'].iloc[0]\n",
    "#真实轨迹\n",
    "real_trajectory = list(data['Grid'].iloc[:trajectory_length])\n",
    "#计算原有方法的加噪轨迹\n",
    "noisy_trajectory = generate_noisy_trajectory(start_point, trajectory_length, transition_matrix, privacy_budget_dict)\n",
    "#计算DP-Star方法生成的加噪轨迹\n",
    "noise_scale_from_original = 0.1 # 与您原函数默认值保持一致\n",
    "# 建立一个合理的反向映射关系来得到epsilon\n",
    "# noise_scale 越大 -> 噪声越大 -> 隐私保护越强 -> epsilon 越小\n",
    "dp_star_epsilon = 1.0 / noise_scale_from_original\n",
    "dp_star_sensitivity = 1 # 对于一阶转移计数，敏感度为1\n",
    "\n",
    "# 直接生成加噪轨迹，方便后续调用\n",
    "dp_star_noisy_trajectory = dp_star_synthesis(\n",
    "    trajectories=trajectories_db, \n",
    "    epsilon=dp_star_epsilon, \n",
    "    start_point=start_point, \n",
    "    length=trajectory_length,\n",
    "    sensitivity=dp_star_sensitivity\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "(10.046071753831791, 10.04987562112089)"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 计算真实轨迹和加噪轨迹的弗雷歇距离\n",
    "frechet_dist = frechet_distance(real_trajectory, noisy_trajectory) #原有方法\n",
    "new_frechet_dist = frechet_distance(real_trajectory, dp_star_noisy_trajectory) #DP-star\n",
    "# 输出结果\n",
    "frechet_dist, new_frechet_dist"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:29.699617900Z",
     "start_time": "2025-06-24T11:51:29.593619800Z"
    }
   },
   "id": "55ad79de-f963-4c11-8563-5715631a67dc"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a52e8424-3505-466e-92c9-490446917a18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:29.980298Z",
     "start_time": "2025-06-24T11:51:29.958552200Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "(100, 100, 0, 100)"
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 轨迹长度验证\n",
    "real_length = len(real_trajectory)\n",
    "generated_length = len(noisy_trajectory)\n",
    "length_difference = abs(real_length - generated_length)\n",
    "\n",
    "dp_star_length = len(dp_star_noisy_trajectory)\n",
    "real_length, generated_length, length_difference, dp_star_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e98f3e20-a730-4cff-9f4d-40a9e7fe72ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:30.366232900Z",
     "start_time": "2025-06-24T11:51:30.357506Z"
    }
   },
   "outputs": [],
   "source": [
    "# 停留时间分布对比\n",
    "real_stay_times = stay_times.groupby('Grid')['Duration'].mean().reset_index()\n",
    "real_stay_times.columns = ['Grid', 'Average_Stay_Time']\n",
    "\n",
    "generated_stay_times = defaultdict(int)\n",
    "for point in noisy_trajectory:\n",
    "    generated_stay_times[tuple(np.floor(point))] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dda9d6b9-3dfb-465e-8de9-2c1b08057b2b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:30.769005800Z",
     "start_time": "2025-06-24T11:51:30.748926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            Grid  Total_Stay_Time  Average_Stay_Time\n0     (1.0, 1.0)                3               0.03\n1    (-1.0, 1.0)                1               0.01\n2   (-1.0, -1.0)                3               0.03\n3     (1.0, 4.0)                3               0.03\n4    (-1.0, 3.0)                2               0.02\n5     (6.0, 3.0)                2               0.02\n6     (2.0, 2.0)                3               0.03\n7    (10.0, 1.0)                1               0.01\n8     (2.0, 1.0)                1               0.01\n9     (3.0, 2.0)                1               0.01\n10    (0.0, 5.0)                5               0.05\n11    (2.0, 6.0)                1               0.01\n12    (6.0, 7.0)                2               0.02\n13    (0.0, 2.0)                1               0.01\n14    (0.0, 7.0)                1               0.01\n15    (1.0, 3.0)                3               0.03\n16    (5.0, 1.0)                1               0.01\n17    (4.0, 2.0)                2               0.02\n18    (1.0, 0.0)                1               0.01\n19    (3.0, 5.0)                1               0.01\n20    (1.0, 6.0)                3               0.03\n21    (0.0, 4.0)                1               0.01\n22    (1.0, 5.0)                3               0.03\n23    (8.0, 5.0)                1               0.01\n24    (4.0, 6.0)                1               0.01\n25    (4.0, 4.0)                1               0.01\n26    (6.0, 4.0)                1               0.01\n27    (0.0, 3.0)                1               0.01\n28   (-1.0, 5.0)                2               0.02\n29   (-1.0, 6.0)                1               0.01\n30   (2.0, -1.0)                1               0.01\n31    (1.0, 2.0)                2               0.02\n32    (0.0, 1.0)                3               0.03\n33    (3.0, 0.0)                3               0.03\n34    (5.0, 4.0)                2               0.02\n35    (6.0, 6.0)                1               0.01\n36    (7.0, 7.0)                1               0.01\n37    (4.0, 0.0)                2               0.02\n38    (6.0, 5.0)                1               0.01\n39    (3.0, 7.0)                1               0.01\n40    (0.0, 0.0)                3               0.03\n41    (5.0, 0.0)                3               0.03\n42    (4.0, 1.0)                1               0.01\n43    (1.0, 7.0)                2               0.02\n44   (1.0, -1.0)                2               0.02\n45    (7.0, 3.0)                1               0.01\n46    (2.0, 3.0)                3               0.03\n47    (3.0, 3.0)                1               0.01\n48    (3.0, 4.0)                1               0.01\n49    (5.0, 3.0)                2               0.02\n50    (2.0, 4.0)                2               0.02\n51    (4.0, 3.0)                1               0.01\n52    (0.0, 6.0)                1               0.01\n53    (5.0, 5.0)                2               0.02\n54   (11.0, 6.0)                1               0.01\n55    (9.0, 7.0)                1               0.01\n56    (7.0, 6.0)                1               0.01\n57    (3.0, 1.0)                1               0.01\n58   (5.0, -1.0)                1               0.01",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grid</th>\n      <th>Total_Stay_Time</th>\n      <th>Average_Stay_Time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>(1.0, 1.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(-1.0, 1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(-1.0, -1.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1.0, 4.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(-1.0, 3.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(6.0, 3.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(2.0, 2.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(10.0, 1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(2.0, 1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(3.0, 2.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>(0.0, 5.0)</td>\n      <td>5</td>\n      <td>0.05</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>(2.0, 6.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>(6.0, 7.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(0.0, 2.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(0.0, 7.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(1.0, 3.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(5.0, 1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>(4.0, 2.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>(1.0, 0.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(3.0, 5.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>(1.0, 6.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>(0.0, 4.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>(1.0, 5.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>(8.0, 5.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>(4.0, 6.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>(4.0, 4.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>(6.0, 4.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>(0.0, 3.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>(-1.0, 5.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>(-1.0, 6.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>(2.0, -1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>(1.0, 2.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>(0.0, 1.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>(3.0, 0.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>(5.0, 4.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>(6.0, 6.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>(7.0, 7.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>(4.0, 0.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>(6.0, 5.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>(3.0, 7.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>(0.0, 0.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>(5.0, 0.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>(4.0, 1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>(1.0, 7.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>(1.0, -1.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>(7.0, 3.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>(2.0, 3.0)</td>\n      <td>3</td>\n      <td>0.03</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>(3.0, 3.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>(3.0, 4.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>(5.0, 3.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>(2.0, 4.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>(4.0, 3.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>(0.0, 6.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>(5.0, 5.0)</td>\n      <td>2</td>\n      <td>0.02</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>(11.0, 6.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>(9.0, 7.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>(7.0, 6.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>(3.0, 1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>(5.0, -1.0)</td>\n      <td>1</td>\n      <td>0.01</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将生成的停留时间转换为DataFrame\n",
    "generated_stay_times_df = (\n",
    "    pd.DataFrame(list(generated_stay_times.items()), columns=['Grid', 'Total_Stay_Time'])\n",
    ")\n",
    "\n",
    "generated_stay_times_df['Average_Stay_Time'] = (\n",
    "    generated_stay_times_df['Total_Stay_Time'] / generated_stay_times_df['Total_Stay_Time'].sum()\n",
    ")\n",
    "generated_stay_times_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "96413c63-dc17-45e7-90e0-eed47b9daa3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:31.130479100Z",
     "start_time": "2025-06-24T11:51:31.118472800Z"
    }
   },
   "outputs": [],
   "source": [
    "# 频繁模式对比\n",
    "real_visit_freq = visit_frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "79cef1b9-ad94-43ec-9038-668a43c0a2f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:31.585271300Z",
     "start_time": "2025-06-24T11:51:31.552207100Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "            Grid  Visit_Frequency\n10    (0.0, 5.0)                5\n0     (1.0, 1.0)                3\n32    (0.0, 1.0)                3\n46    (2.0, 3.0)                3\n15    (1.0, 3.0)                3\n41    (5.0, 0.0)                3\n20    (1.0, 6.0)                3\n22    (1.0, 5.0)                3\n33    (3.0, 0.0)                3\n6     (2.0, 2.0)                3\n40    (0.0, 0.0)                3\n3     (1.0, 4.0)                3\n2   (-1.0, -1.0)                3\n34    (5.0, 4.0)                2\n28   (-1.0, 5.0)                2\n43    (1.0, 7.0)                2\n44   (1.0, -1.0)                2\n31    (1.0, 2.0)                2\n49    (5.0, 3.0)                2\n12    (6.0, 7.0)                2\n53    (5.0, 5.0)                2\n4    (-1.0, 3.0)                2\n5     (6.0, 3.0)                2\n50    (2.0, 4.0)                2\n37    (4.0, 0.0)                2\n17    (4.0, 2.0)                2\n45    (7.0, 3.0)                1\n52    (0.0, 6.0)                1\n51    (4.0, 3.0)                1\n47    (3.0, 3.0)                1\n42    (4.0, 1.0)                1\n54   (11.0, 6.0)                1\n55    (9.0, 7.0)                1\n56    (7.0, 6.0)                1\n57    (3.0, 1.0)                1\n48    (3.0, 4.0)                1\n39    (3.0, 7.0)                1\n38    (6.0, 5.0)                1\n29   (-1.0, 6.0)                1\n36    (7.0, 7.0)                1\n35    (6.0, 6.0)                1\n7    (10.0, 1.0)                1\n8     (2.0, 1.0)                1\n9     (3.0, 2.0)                1\n11    (2.0, 6.0)                1\n13    (0.0, 2.0)                1\n14    (0.0, 7.0)                1\n16    (5.0, 1.0)                1\n18    (1.0, 0.0)                1\n19    (3.0, 5.0)                1\n21    (0.0, 4.0)                1\n23    (8.0, 5.0)                1\n24    (4.0, 6.0)                1\n25    (4.0, 4.0)                1\n26    (6.0, 4.0)                1\n27    (0.0, 3.0)                1\n1    (-1.0, 1.0)                1\n30   (2.0, -1.0)                1\n58   (5.0, -1.0)                1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Grid</th>\n      <th>Visit_Frequency</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>10</th>\n      <td>(0.0, 5.0)</td>\n      <td>5</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>(1.0, 1.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>(0.0, 1.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>(2.0, 3.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>(1.0, 3.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>(5.0, 0.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>(1.0, 6.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>(1.0, 5.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>(3.0, 0.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>(2.0, 2.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>(0.0, 0.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>(1.0, 4.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>(-1.0, -1.0)</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>(5.0, 4.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>(-1.0, 5.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>(1.0, 7.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>(1.0, -1.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>(1.0, 2.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>(5.0, 3.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>(6.0, 7.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>53</th>\n      <td>(5.0, 5.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>(-1.0, 3.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>(6.0, 3.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>50</th>\n      <td>(2.0, 4.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>(4.0, 0.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>(4.0, 2.0)</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>(7.0, 3.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>52</th>\n      <td>(0.0, 6.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>51</th>\n      <td>(4.0, 3.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>(3.0, 3.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>(4.0, 1.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>54</th>\n      <td>(11.0, 6.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>55</th>\n      <td>(9.0, 7.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>56</th>\n      <td>(7.0, 6.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>(3.0, 1.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>(3.0, 4.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>(3.0, 7.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>(6.0, 5.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>(-1.0, 6.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>(7.0, 7.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>(6.0, 6.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>(10.0, 1.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>(2.0, 1.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>(3.0, 2.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>(2.0, 6.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>(0.0, 2.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>(0.0, 7.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>(5.0, 1.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>(1.0, 0.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>(3.0, 5.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>(0.0, 4.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>(8.0, 5.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>(4.0, 6.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>(4.0, 4.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>(6.0, 4.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>(0.0, 3.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>(-1.0, 1.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>(2.0, -1.0)</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>58</th>\n      <td>(5.0, -1.0)</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 生成轨迹的访问频次\n",
    "generated_visit_freq = defaultdict(int)\n",
    "for point in noisy_trajectory:\n",
    "    grid_point = tuple(np.floor(point))\n",
    "    generated_visit_freq[grid_point] += 1\n",
    "\n",
    "generated_visit_freq_df = (\n",
    "    pd.DataFrame(list(generated_visit_freq.items()), columns=['Grid', 'Visit_Frequency'])\n",
    "    .sort_values(by='Visit_Frequency', ascending=False)\n",
    ")\n",
    "generated_visit_freq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "# --- 新增代码：计算 DP-Star 轨迹的访问频次 ---\n",
    "\n",
    "# dp_star_noisy_trajectory 包含的是离散的整数网格点，无需 np.floor\n",
    "dp_star_visit_freq = defaultdict(int)\n",
    "for point in dp_star_noisy_trajectory:\n",
    "    # point 本身就是元组 (e.g., (1, 1))，可以直接作为字典的键\n",
    "    dp_star_visit_freq[point] += 1\n",
    "\n",
    "# 将统计结果转换为 DataFrame\n",
    "dp_star_visit_freq_df = (\n",
    "    pd.DataFrame(list(dp_star_visit_freq.items()), columns=['Grid', 'Visit_Frequency'])\n",
    "    .sort_values(by='Visit_Frequency', ascending=False)\n",
    ")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:31.980933500Z",
     "start_time": "2025-06-24T11:51:31.970457900Z"
    }
   },
   "id": "145b3ad1ba479b05"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基础方法的 VFE%: 9027871.87%\n",
      "DP-Star 方法的 VFE%: 99.47%\n"
     ]
    }
   ],
   "source": [
    "# --- 新增代码：实现 VFE% 计算 ---\n",
    "\n",
    "def calculate_vfe_percentage(real_freq_dict, noisy_freq_dict, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    根据论文中的公式 (10) 计算访问频率误差百分比 (VFE%)。\n",
    "\n",
    "    参数:\n",
    "    real_freq_dict (dict): 真实轨迹的访问频次字典 {grid: count}\n",
    "    noisy_freq_dict (dict): 加噪轨迹的访问频次字典 {grid: count}\n",
    "    epsilon (float): 防止除以零的小常数\n",
    "\n",
    "    返回:\n",
    "    float: VFE% 的值\n",
    "    \"\"\"\n",
    "    # 获取所有涉及到的网格（并集）\n",
    "    all_grids = set(real_freq_dict.keys()) | set(noisy_freq_dict.keys())\n",
    "    \n",
    "    if not all_grids:\n",
    "        return 0.0  # 如果没有网格，则误差为0\n",
    "\n",
    "    N = len(all_grids)\n",
    "    total_relative_error = 0.0\n",
    "\n",
    "    for grid in all_grids:\n",
    "        c_real = real_freq_dict.get(grid, 0)   # 如果网格不在真实轨迹中，频次为0\n",
    "        c_noisy = noisy_freq_dict.get(grid, 0) # 如果网格不在加噪轨迹中，频次为0\n",
    "\n",
    "        # 计算单个网格的绝对差值\n",
    "        abs_diff = abs(c_noisy - c_real)\n",
    "        \n",
    "        # 计算单个网格的相对误差\n",
    "        # 注意分母是真实频次\n",
    "        relative_error = abs_diff / (c_real + epsilon)\n",
    "        \n",
    "        total_relative_error += relative_error\n",
    "\n",
    "    # 计算平均相对误差并转换为百分比\n",
    "    vfe_percent = (total_relative_error / N) * 100\n",
    "    \n",
    "    return vfe_percent\n",
    "\n",
    "# --- 调用函数进行计算 ---\n",
    "\n",
    "# 1. 计算 \"您的基础方法\" 的 VFE%\n",
    "# 您的代码中已经有了 real_visit_freq 和 generated_visit_freq\n",
    "# real_visit_freq 是 DataFrame，我们先转成字典\n",
    "real_visit_freq_dict = dict(zip(real_visit_freq['Grid'], real_visit_freq['Visit_Frequency']))\n",
    "# generated_visit_freq 是 defaultdict，可以直接使用\n",
    "vfe_original_method = calculate_vfe_percentage(real_visit_freq_dict, generated_visit_freq)\n",
    "\n",
    "\n",
    "# 2. 计算 \"DP-Star 方法\" 的 VFE%\n",
    "# 假设您已经按照我之前的建议计算了 dp_star_visit_freq\n",
    "vfe_dp_star_method = calculate_vfe_percentage(real_visit_freq_dict, dp_star_visit_freq)\n",
    "\n",
    "\n",
    "# --- 打印结果 ---\n",
    "print(f\"基础方法的 VFE%: {vfe_original_method:.2f}%\")\n",
    "print(f\"DP-Star 方法的 VFE%: {vfe_dp_star_method:.2f}%\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T11:51:32.699052600Z",
     "start_time": "2025-06-24T11:51:32.679820100Z"
    }
   },
   "id": "527a096d6e17dee5"
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "基础方法的 STD: 0.7734\n",
      "DP-Star 方法的 STD: 0.8442\n"
     ]
    }
   ],
   "source": [
    "def calculate_stay_time_stats(trajectory_series):\n",
    "    \"\"\"\n",
    "    计算轨迹中每个网格的所有停留时长。\n",
    "\n",
    "    参数:\n",
    "    trajectory_series (pd.Series): 包含轨迹点的 Pandas Series.\n",
    "\n",
    "    返回:\n",
    "    dict: 一个字典，键是网格点，值是该网格所有停留时长的列表。\n",
    "          e.g., {(1, 1): [3, 5], (1, 2): [2]}\n",
    "    \"\"\"\n",
    "    # 识别连续停留的“块”\n",
    "    stay_blocks = (trajectory_series != trajectory_series.shift(1)).cumsum()\n",
    "    \n",
    "    # 创建临时 DataFrame\n",
    "    temp_df = pd.DataFrame({\n",
    "        'Grid': trajectory_series,\n",
    "        'Stay_Block': stay_blocks\n",
    "    })\n",
    "    \n",
    "    # 计算每个“块”的持续时间（即一次停留的时长）\n",
    "    stay_durations = temp_df.groupby(['Grid', 'Stay_Block']).size().reset_index(name='Duration')\n",
    "    \n",
    "    # 聚合每个网格的所有停留时长\n",
    "    stay_time_dict = defaultdict(list)\n",
    "    for _, row in stay_durations.iterrows():\n",
    "        stay_time_dict[row['Grid']].append(row['Duration'])\n",
    "        \n",
    "    return dict(stay_time_dict)\n",
    "\n",
    "\n",
    "def calculate_std(real_stay_dict, noisy_stay_dict):\n",
    "    \"\"\"\n",
    "    根据论文中的公式 (9) 计算停留时间差异 (STD)。\n",
    "\n",
    "    参数:\n",
    "    real_stay_dict (dict): 真实轨迹的停留时长字典.\n",
    "    noisy_stay_dict (dict): 加噪轨迹的停留时长字典.\n",
    "\n",
    "    返回:\n",
    "    float: STD 的值.\n",
    "    \"\"\"\n",
    "    # 1. 计算每个网格的平均停留时间\n",
    "    avg_real_stay = {grid: np.mean(durations) for grid, durations in real_stay_dict.items()}\n",
    "    avg_noisy_stay = {grid: np.mean(durations) for grid, durations in noisy_stay_dict.items()}\n",
    "    \n",
    "    # 2. 确定 M：具有逗留行为的网格集合\n",
    "    # 论文定义为 \"lingering behavior\"，我们理解为停留时间 > 1 的情况。\n",
    "    # 这里的实现是：只要在任一轨迹中发生过停留，就计入。\n",
    "    lingering_grids = set(real_stay_dict.keys()) | set(noisy_stay_dict.keys())\n",
    "    \n",
    "    if not lingering_grids:\n",
    "        return 0.0\n",
    "        \n",
    "    M = len(lingering_grids)\n",
    "    total_abs_diff = 0.0\n",
    "    \n",
    "    # 3. 循环计算差值总和\n",
    "    for grid in lingering_grids:\n",
    "        t_real = avg_real_stay.get(grid, 0)\n",
    "        t_noisy = avg_noisy_stay.get(grid, 0)\n",
    "        total_abs_diff += abs(t_noisy - t_real)\n",
    "        \n",
    "    # 4. 计算平均差值\n",
    "    std_value = total_abs_diff / M\n",
    "    \n",
    "    return std_value\n",
    "\n",
    "# --- 调用函数进行计算 ---\n",
    "\n",
    "# 1. 为真实轨迹、基础方法轨迹、DP-Star 轨迹准备 Series\n",
    "# 注意：noisy_trajectory 是浮点数，需要先取整\n",
    "real_traj_series = pd.Series(real_trajectory)\n",
    "noisy_traj_series_int = pd.Series([tuple(np.floor(p)) for p in noisy_trajectory])\n",
    "dp_star_traj_series = pd.Series(dp_star_noisy_trajectory)\n",
    "\n",
    "# 2. 计算每个轨迹的停留统计\n",
    "real_stay_stats = calculate_stay_time_stats(real_traj_series)\n",
    "noisy_stay_stats = calculate_stay_time_stats(noisy_traj_series_int)\n",
    "dp_star_stay_stats = calculate_stay_time_stats(dp_star_traj_series)\n",
    "\n",
    "# 3. 计算 STD\n",
    "std_original_method = calculate_std(real_stay_stats, noisy_stay_stats)\n",
    "std_dp_star_method = calculate_std(real_stay_stats, dp_star_stay_stats)\n",
    "\n",
    "# --- 打印结果 ---\n",
    "print(f\"基础方法的 STD: {std_original_method:.4f}\")\n",
    "print(f\"DP-Star 方法的 STD: {std_dp_star_method:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-24T09:04:06.701954700Z",
     "start_time": "2025-06-24T09:04:06.673238300Z"
    }
   },
   "id": "cb4548167fe83542"
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "2d44e0ab-95f3-4330-b2ce-9f32568d4725",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:27:47.478258500Z",
     "start_time": "2025-06-17T14:27:47.461417100Z"
    }
   },
   "outputs": [],
   "source": [
    "# 转移模式对比\n",
    "# 构建加噪轨迹的转移矩阵\n",
    "generated_transition_counts = defaultdict(lambda: defaultdict(int))\n",
    "for i in range(len(noisy_trajectory) - 1):\n",
    "    current_state = tuple(np.floor(noisy_trajectory[i]))\n",
    "    next_state = tuple(np.floor(noisy_trajectory[i + 1]))\n",
    "    generated_transition_counts[current_state][next_state] += 1\n",
    "\n",
    "generated_transition_matrix = {\n",
    "    state: {\n",
    "        next_state: count / sum(next_states.values())\n",
    "        for next_state, count in next_states.items()\n",
    "    }\n",
    "    for state, next_states in generated_transition_counts.items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "e38d34d2-95a3-4140-b732-ad2654a9dfb6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:27:47.492509100Z",
     "start_time": "2025-06-17T14:27:47.478258500Z"
    }
   },
   "outputs": [],
   "source": [
    "# 超参数影响分析\n",
    "def analyze_impact(privacy_budget_scale, noise_scale):\n",
    "    \"\"\"\n",
    "    调整隐私预算和噪声强度，观察对相似度和效用的影响\n",
    "    \"\"\"\n",
    "    scaled_privacy_budget = {\n",
    "        grid: budget * privacy_budget_scale for grid, budget in privacy_budget_dict.items()\n",
    "    }\n",
    "\n",
    "    # 生成加噪轨迹\n",
    "    noisy_trajectory_scaled = generate_noisy_trajectory(\n",
    "        start_point, trajectory_length, transition_matrix, scaled_privacy_budget, noise_scale\n",
    "    )\n",
    "\n",
    "    # 计算弗雷歇距离\n",
    "    scaled_frechet_dist = frechet_distance(real_trajectory, noisy_trajectory_scaled)\n",
    "\n",
    "    # 返回结果\n",
    "    return {\n",
    "        'Privacy_Budget_Scale': privacy_budget_scale,\n",
    "        'Noise_Scale': noise_scale,\n",
    "        'Frechet_Distance': scaled_frechet_dist\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8653b40c-3f25-4b9c-a8b4-ff89c4e8cb31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:27:47.508053600Z",
     "start_time": "2025-06-17T14:27:47.492509100Z"
    }
   },
   "outputs": [],
   "source": [
    "# 测试不同隐私预算和噪声强度\n",
    "impact_results = []\n",
    "for budget_scale in [0.5, 1, 2]:\n",
    "    for noise in [0.05, 0.1, 0.2]:\n",
    "        result = analyze_impact(budget_scale, noise)\n",
    "        impact_results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "be91df28-a294-4f91-be28-a83c87e48523",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-17T14:27:47.525680700Z",
     "start_time": "2025-06-17T14:27:47.510262700Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'Length_Difference': 98,\n 'Stay_Time_Comparison':          Grid  Total_Stay_Time  Average_Stay_Time\n 0  (1.0, 1.0)                1                0.5\n 1  (0.0, 6.0)                1                0.5,\n 'Visit_Frequency_Comparison':          Grid  Visit_Frequency\n 0  (1.0, 1.0)                1\n 1  (0.0, 6.0)                1,\n 'Impact_Analysis': [{'Privacy_Budget_Scale': 0.5,\n   'Noise_Scale': 0.05,\n   'Frechet_Distance': 6.082762530298219},\n  {'Privacy_Budget_Scale': 0.5,\n   'Noise_Scale': 0.1,\n   'Frechet_Distance': 4.12222521724227},\n  {'Privacy_Budget_Scale': 0.5,\n   'Noise_Scale': 0.2,\n   'Frechet_Distance': 5.099194777967546},\n  {'Privacy_Budget_Scale': 1,\n   'Noise_Scale': 0.05,\n   'Frechet_Distance': 6.082762530298219},\n  {'Privacy_Budget_Scale': 1,\n   'Noise_Scale': 0.1,\n   'Frechet_Distance': 7.802381591549775},\n  {'Privacy_Budget_Scale': 1,\n   'Noise_Scale': 0.2,\n   'Frechet_Distance': 6.082762530298219},\n  {'Privacy_Budget_Scale': 2,\n   'Noise_Scale': 0.05,\n   'Frechet_Distance': 6.001609336668912},\n  {'Privacy_Budget_Scale': 2,\n   'Noise_Scale': 0.1,\n   'Frechet_Distance': 6.082762530298219},\n  {'Privacy_Budget_Scale': 2,\n   'Noise_Scale': 0.2,\n   'Frechet_Distance': 4.1280438524624605}]}"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 结果输出\n",
    "{\n",
    "    \"Length_Difference\": length_difference,\n",
    "    \"Stay_Time_Comparison\": generated_stay_times_df.head(),\n",
    "    \"Visit_Frequency_Comparison\": generated_visit_freq_df.head(),\n",
    "    \"Impact_Analysis\": impact_results\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "40d4403825f0dabc"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "2f15b93947579c97"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "69a3ec981ead4473"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
